{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import nerf_model\n",
    "import dataloader\n",
    "import nerf_helpers\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a79a76",
   "metadata": {},
   "source": [
    "### Visualizing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a371fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(coords, rgb): \n",
    "    a, b = coords.shape\n",
    "    if b == 3:\n",
    "        coords = coords.T\n",
    "    if type(rgb) != str:\n",
    "        a, b = rgb.shape\n",
    "        if a == 3:\n",
    "            rgb = rgb.T\n",
    "    plot_fig = go.Scatter3d(x=coords[0], y=coords[1], z=coords[2], \n",
    "    mode='markers', marker=dict(\n",
    "       size=2,\n",
    "       color=rgb\n",
    "    ),)\n",
    "    return plot_fig\n",
    "\n",
    "def line_visualize(coords, rgb): \n",
    "    a, b = coords.shape\n",
    "    if b == 3:\n",
    "        coords = coords.T\n",
    "    if type(rgb) != str:\n",
    "        rgb = rgb.T\n",
    "    plot_fig = go.Scatter3d(x=coords[0], y=coords[1], z=coords[2], \n",
    "    mode='lines', line=dict(\n",
    "       width=1,\n",
    "       color=rgb\n",
    "    ),)\n",
    "    return plot_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c0c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "for i, batch in enumerate(iter(sdl)):\n",
    "    if i < 5:\n",
    "        continue\n",
    "    gc.collect()\n",
    "    nerf_helpers.fix_batchify(batch)\n",
    "    origins = batch['all_origin'].reshape((-1,3))[::10,:]\n",
    "    direcs = batch['all_direc'].reshape((-1, 3))[::10,:]\n",
    "    images = batch['image'].reshape((-1, 3))[::10,:]\n",
    "    im_coords = origins + 6 * direcs\n",
    "    pic = visualize(im_coords, images)\n",
    "    o = visualize(origins[0,None,:], 'purple')\n",
    "    fig.add_trace(pic)\n",
    "    fig.add_trace(o)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e84af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "for i, batch in enumerate(iter(sdl)):\n",
    "    if i == 2:\n",
    "        break\n",
    "    gc.collect()\n",
    "    nerf_helpers.fix_batchify(batch)\n",
    "    origins = batch['all_origin'][200:600,200:600,:].reshape((-1,3))[::300,:]\n",
    "    direcs = batch['all_direc'][200:600,200:600,:].reshape((-1, 3))[::300,:]\n",
    "    images = batch['image'][200:600,200:600,:].reshape((-1, 3))[::300,:]\n",
    "    \n",
    "    samples, ts = nerf_helpers.generate_coarse_samples(origins, direcs, 16)\n",
    "    rgb = torch.broadcast_to(images[:, None, :], samples.shape)\n",
    "    rgb = rgb.reshape((-1,3)).T\n",
    "    samples = samples.view((-1,3))\n",
    "    pic = line_visualize(samples, rgb)\n",
    "    o = visualize(origins[0,None,:], 'purple')\n",
    "    fig.add_trace(pic)\n",
    "    fig.add_trace(o)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf020dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform_sampling(o_rays: torch.Tensor, d_rays: torch.Tensor, weights, ts, num_samples):\n",
    "    \"\"\"Performs inverse transform sampling according to the weights.\n",
    "\n",
    "    Samples from ts according to the weights (i.e. ts with higher weights are \n",
    "    more likely to be sampled).\n",
    "    \n",
    "    Probably not the best implementation, since the official NeRF implementation \n",
    "    does something different. This is probably good enough though? Good thing\n",
    "    I don't have to be rigorous. \n",
    "\n",
    "    Args:\n",
    "        o_rays: [N x 3] coordinates of the ray origin.\n",
    "        d_rays: [N x 3] directions of the ray.\n",
    "        weights: [N x C x 1] tensor of weights calculated as \n",
    "                 w = T(1 - exp(- density * delta)). N is the batch size, and C \n",
    "                 is the number of coarse samples.\n",
    "        ts: [N x C x 1] is the increment between each sample. N is the batch \n",
    "            size, and C is the number of coarse samples. \n",
    "        num_samples: number of samples to return per ray.\n",
    "    Returns:\n",
    "        fine_samples: [N x num_samples x 3] tensor sampled according to weights.\n",
    "                      Instead of using the same values as in ts, we pertube it by \n",
    "                      adding random noise (sampled from U(0, 1/num_samples)).\n",
    "        fine_ts: [N x num_samples x 1] tensor of the time increment for each sample. \n",
    "    \"\"\"\n",
    "    N, C, _ = ts.shape\n",
    "    o_rays = o_rays.unsqueeze(1)\n",
    "    d_rays = d_rays.unsqueeze(1)\n",
    "\n",
    "    cdf = torch.cumsum(weights, axis=1)  # [N x C x 1]\n",
    "    cdf = cdf / cdf[:, -1, None]\n",
    "    eps = torch.rand((N, 1), device=device) / num_samples  # low variance sampling\n",
    "    samples = torch.arange(0, 1, 1 / num_samples, device = device)\n",
    "    samples = torch.broadcast_to(samples, (N, num_samples))\n",
    "    samples = samples + eps\n",
    "\n",
    "    cdf = torch.squeeze(cdf, -1)  # make dimensions match, [N x C]\n",
    "    idxs = torch.searchsorted(cdf, samples).unsqueeze(-1)  # [N x C x 1]\n",
    "    idxs[idxs >= C] = C - 1\n",
    "    bins = torch.gather(ts, 1, idxs)\n",
    "    \n",
    "    fine_ts = bins + 2 * torch.rand((N, num_samples, 1), device=device) / C # num_samples\n",
    "    fine_samples = o_rays + fine_ts * d_rays\n",
    "    return fine_samples, fine_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7c736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "coarse_samples, coarse_ts = nerf_helpers.generate_coarse_samples(o_rays, d_rays, 64, 2., 6.)\n",
    "weights = torch.arange(1, 65, 1).view(coarse_ts.shape)\n",
    "\n",
    "num_samples = 128\n",
    "fine_samples, fine_ts = sample_pdf(o_rays, d_rays, weights, coarse_ts, num_samples)\n",
    "\n",
    "print(fine_samples.shape)\n",
    "# print(fine_samples)\n",
    "pic = visualize(fine_samples.view((-1,3)), 'black')\n",
    "o = visualize(o_rays[0,None,:], 'purple')\n",
    "\n",
    "fig.add_trace(pic)\n",
    "fig.add_trace(o)\n",
    "fig.show()\n",
    "# print(fine_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a3870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "coarse_samples, coarse_ts = nerf_helpers.generate_coarse_samples(o_rays, d_rays, 64, 2., 6.)\n",
    "weights = torch.arange(1, 65, 1).view(coarse_ts.shape)\n",
    "\n",
    "num_samples = 128\n",
    "fine_samples, fine_ts = nerf_helpers.inverse_transform_sampling(o_rays, d_rays, weights, coarse_ts, num_samples)\n",
    "\n",
    "print(fine_samples.shape)\n",
    "# print(fine_samples)\n",
    "pic = visualize(fine_samples.view((-1,3)), 'black')\n",
    "cpic = visualize(coarse_samples.view((-1,3)), 'red')\n",
    "o = visualize(o_rays[0,None,:], 'purple')\n",
    "\n",
    "fig.add_trace(pic)\n",
    "fig.add_trace(cpic)\n",
    "fig.add_trace(o)\n",
    "fig.show()\n",
    "# print(fine_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787b0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Histogram(x=fine_ts.view((-1,))))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b124f20b",
   "metadata": {},
   "source": [
    "### Model Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "dataloader = reload(dataloader)\n",
    "nerf_model = reload(nerf_model)\n",
    "nerf_helpers = reload(nerf_helpers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a63d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/lego/'\n",
    "sdl = dataloader.getSyntheticDataloader(base_dir, 'val', 1, num_workers=1, shuffle=True)\n",
    "\n",
    "batch = next(iter(sdl))\n",
    "nerf_helpers.fix_batchify(batch)\n",
    "print(batch.keys())\n",
    "print(batch['rgb'].shape)\n",
    "print(batch['origin'].shape)\n",
    "print(batch['direc'].shape)\n",
    "print(batch['xs'].shape)\n",
    "\n",
    "o_rays = batch['origin']\n",
    "d_rays = batch['direc']\n",
    "rgb = batch['rgb']\n",
    "xs = batch['xs']\n",
    "ys = batch['ys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nerf_model.NeRFNetwork(position_dim=10, direction_dim=4, coarse_samples=64,\n",
    "                 fine_samples=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66314775",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train()\n",
    "pred_dict = network.forward(o_rays, d_rays)\n",
    "fine_rgbs = pred_dict['fine_rgb_rays']\n",
    "coarse_rgbs = pred_dict['coarse_rgb_rays']\n",
    "\n",
    "fine_loss = F.mse_loss(fine_rgbs, rgb)\n",
    "coarse_loss = F.mse_loss(coarse_rgbs, rgb)\n",
    "loss = coarse_loss + fine_loss\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b298230",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bff79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['coarse_ts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4977dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['coarse_deltas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345e7daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = torch.nn.Linear(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70724230",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi = torch.Tensor([[[1.,2.],[3.,4.]]])\n",
    "single = torch.Tensor([[1.,2.],[3.,4.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f5d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc(multi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde27d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc(single)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

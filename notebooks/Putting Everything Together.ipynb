{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1024667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import nerf_model\n",
    "import dataloader\n",
    "import nerf_helpers\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import gc\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00efb5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_random_coordinates(N, height, width, alpha=None, proportion=0.5): \n",
    "    \"\"\"Two [N,] torch tensors representing random coordinates.\n",
    "\n",
    "    Args:\n",
    "        N: int representing number of coordinates to sample\n",
    "        height: the maximum height value (exclusive)\n",
    "        width: maximum width value (exclusive)\n",
    "        alpha: alpha channel of an image, used to weight coordinates to sample.\n",
    "               No weighting if None.\n",
    "        proportion: proportion of coordinates that have to have alpha values > 0.\n",
    "    Returns:\n",
    "        xs: [N,] torch tensor of random ints [0,width)\n",
    "        ys: [N,] torch tensor of random ints [0,height)\n",
    "    \"\"\"\n",
    "    if alpha == None:\n",
    "        xs = torch.randint(0, width, size=(N,))\n",
    "        ys = torch.randint(0, height, size=(N,))\n",
    "    else: \n",
    "        num_in_alpha = int(N * proportion)\n",
    "        num_random = N - num_in_alpha\n",
    "        xs = torch.randint(0, width, size=(num_random*2,))\n",
    "        ys = torch.randint(0, height, size=(num_random*2,))\n",
    "        valid = alpha[ys, xs]\n",
    "        xs = xs[valid]; ys = ys[valid]\n",
    "        if xs.shape[0] > num_in_alpha:\n",
    "            xs = xs[:num_in_alpha]; ys = ys[:num_in_alpha]\n",
    "        xs = torch.randint(0, width, size=(num_random,))\n",
    "        ys = torch.randint(0, height, size=(num_random,))\n",
    "\n",
    "    return xs, ys\n",
    "\n",
    "alpha = torch.rand((800,800), dtype=torch.bool)\n",
    "\n",
    "sample_random_coordinates(4096, 800, 800, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a371fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(coords, rgb): \n",
    "    a, b = coords.shape\n",
    "    if b == 3:\n",
    "        coords = coords.T\n",
    "    if type(rgb) != str:\n",
    "        rgb = rgb.T\n",
    "    plot_fig = go.Scatter3d(x=coords[0], y=coords[1], z=coords[2], \n",
    "    mode='markers', marker=dict(\n",
    "       size=2,\n",
    "       color=rgb\n",
    "    ))\n",
    "    return plot_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e84af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "for batch in iter(sdl):\n",
    "    gc.collect()\n",
    "\n",
    "    origins = batch['all_origin'].view((-1,3))[::10,:]\n",
    "    direcs = batch['all_direc'].view((-1, 3))[::10,:]\n",
    "\n",
    "    points = origins + direcs\n",
    "\n",
    "    pic = visualize(points, 'pink')\n",
    "    o = visualize(origins, 'black')\n",
    "    fig.add_trace(pic)\n",
    "    fig.add_trace(o)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7a63d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_dir = '../data/lego/'\n",
    "sdl = dataloader.getSyntheticDataloader(base_dir, 'train', 4096, num_workers=1, shuffle=True)\n",
    "\n",
    "batch = next(iter(sdl))\n",
    "nerf_helpers.fix_batchify(batch)\n",
    "print(batch.keys())\n",
    "print(batch['rgb'].shape)\n",
    "print(batch['origin'].shape)\n",
    "print(batch['direc'].shape)\n",
    "print(batch['xs'].shape)\n",
    "# print(batch['all_origin'].shape)\n",
    "\n",
    "o_rays = batch['origin']\n",
    "d_rays = batch['direc']\n",
    "rgb = batch['rgb']\n",
    "xs = batch['xs']\n",
    "ys = batch['ys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52456ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "o_rays, d_rays, rgb = _crop_rays_outside_center(0, xs, ys, o_rays, d_rays, rgb, edge_width=150)\n",
    "print(o_rays.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d501dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop_rays_outside_center(cropping, xs, ys, o_rays, d_rays, rgb, edge_width=150):\n",
    "    \"\"\"Rejects any samples that are outside of the edge with for the next self.cropping iterations. \n",
    "\n",
    "    Sampling towards the center when starting training is beneficial because \n",
    "    border rgb pixels are (0,0,0) which are not helpful for training. I wanted to\n",
    "    put this in the dataloader itself, but there's no good ways to keep track of num. \n",
    "    iters in the dataloader since it resets every epoch. Hence I put it in the trainer module.\n",
    "\n",
    "    Args:\n",
    "        xs: [N,] torch tensor of random ints [0,width)\n",
    "        ys: [N,] torch tensor of random ints [0,height)\n",
    "        o_rays: [N x 3] coordinates of the ray origin.\n",
    "        d_rays: [N x 3] directions of the ray.\n",
    "        rgb: [N x 3] tensor of colors.\n",
    "        edge_width: any pixel from the outer edge of the image to the edge_width inwards\n",
    "                    is removed.\n",
    "        Returns:\n",
    "            o_rays, d_rays, and rgb but only in the indices within bounds.\n",
    "    \"\"\"\n",
    "    if cropping > 0:\n",
    "        IM_HEIGHT = 800 \n",
    "        IM_WIDTH = 800\n",
    "        x_idxs = torch.logical_and(xs > edge_width, xs < IM_WIDTH - edge_width)\n",
    "        y_idxs = torch.logical_and(ys > edge_width, ys < IM_HEIGHT - edge_width)\n",
    "        idxs = torch.logical_and(x_idxs, y_idxs)\n",
    "        o_rays = o_rays[idxs,:] \n",
    "        d_rays = d_rays[idxs,:]\n",
    "        rgb = rgb[idxs,:]\n",
    "        cropping -= 1\n",
    "    return o_rays, d_rays, rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57256e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in range(2): \n",
    "    for batch in tqdm(iter(sdl)):\n",
    "        no_cropping = (batch['xs'] > 600).sum() + (batch['xs'] < 200).sum().item()\n",
    "        print(\"hi\")\n",
    "        if no_cropping > 0: \n",
    "            print(idx)\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42518c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_fn = network.coarse_network\n",
    "print(list(coarse_fn.density_fn.children()))\n",
    "use_relu = list(coarse_fn.density_fn.children())[:-1] + [torch.nn.ReLU()]\n",
    "torch.nn.Sequential(*use_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9f840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "dataloader = reload(dataloader)\n",
    "nerf_model = reload(nerf_model)\n",
    "nerf_helpers = reload(nerf_helpers)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3812cfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nerf_model.NeRFNetwork(position_dim=10, direction_dim=4, coarse_samples=64,\n",
    "                 fine_samples=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66314775",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train()\n",
    "pred_dict = network.forward(o_rays, d_rays)\n",
    "pred_rgbs = pred_dict['pred_rgbs']\n",
    "loss = F.mse_loss(pred_rgbs, rgb)\n",
    "loss.backward()\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d716508c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in network.coarse_network.parameters():\n",
    "    print(torch.linalg.norm(param.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b8ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in network.fine_network.parameters():\n",
    "    print(torch.linalg.norm(param.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((pred_dict['all_density'] == 0.0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57ed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dict['all_density'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc49960",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pred_dict['all_density'] < 0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
